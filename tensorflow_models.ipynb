{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46c15741-d048-46b7-8ba9-56bdd9dc7782",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-05 21:23:03.780731: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-11-05 21:23:03.807770: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Dropout, Flatten\n",
    "from keras.applications.resnet import ResNet50, preprocess_input,ResNet101\n",
    "from keras.applications.mobilenet_v2 import MobileNetV2\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.densenet import DenseNet121\n",
    "from keras.applications.resnet import ResNet50, ResNet101\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.applications.densenet import DenseNet121, DenseNet169, DenseNet201\n",
    "from keras.applications.xception import Xception\n",
    "from keras.preprocessing import image\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix,classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b391243",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 720 images belonging to 2 classes.\n",
      "Found 1000 images belonging to 2 classes.\n",
      "Found 1800 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import image\n",
    "from keras.applications.inception_v3 import preprocess_input\n",
    "\n",
    "\n",
    "# CT scan dataset paths\n",
    "ct_train_path = \"/u/45/muhammu2/data/Desktop/train/\"\n",
    "ct_validation_path = \"/u/45/muhammu2/data/Desktop/validation/\"\n",
    "ct_test_path = \"/u/45/muhammu2/data/Desktop/test/\"\n",
    "\n",
    "# Number of classes depends on the dataset (2 for the CT scan)\n",
    "ct_num_classes = 2\n",
    "\n",
    "# Image size depends on the pretrained model (224 for InceptionV3)\n",
    "image_size = 224\n",
    "batch_size = 16\n",
    "epoch_num = 15\n",
    "\n",
    "# Define a data generator for CT scan training\n",
    "ct_train_datagen = image.ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    vertical_flip=True,\n",
    "    horizontal_flip=True,\n",
    "    preprocessing_function=preprocess_input)\n",
    "\n",
    "ct_train_generator = ct_train_datagen.flow_from_directory(\n",
    "    ct_train_path,\n",
    "    target_size=(image_size, image_size),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "# Define a data generator for CT scan validation\n",
    "ct_validation_generator = ct_train_datagen.flow_from_directory(\n",
    "    ct_validation_path,\n",
    "    target_size=(image_size, image_size),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "# Define a data generator for CT scan testing\n",
    "ct_test_datagen = image.ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    preprocessing_function=preprocess_input)\n",
    "\n",
    "ct_test_generator = ct_test_datagen.flow_from_directory(\n",
    "    ct_test_path,\n",
    "    target_size=(image_size, image_size),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb09d0cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-05 21:23:11.940342: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-05 21:23:12.052127: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-05 21:23:12.052347: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-05 21:23:12.053668: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-05 21:23:12.053812: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-05 21:23:12.053904: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-05 21:23:12.143800: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-05 21:23:12.144257: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-05 21:23:12.144327: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-05 21:23:12.144390: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6011 MB memory:  -> device: 0, name: NVIDIA RTX A2000 8GB Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " mobilenetv2_1.00_224 (Func  (None, 1280)              2257984   \n",
      " tional)                                                         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2)                 2562      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2260546 (8.62 MB)\n",
      "Trainable params: 2562 (10.01 KB)\n",
      "Non-trainable params: 2257984 (8.61 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\t#Create model\n",
    "\tmodel = Sequential()\n",
    "\t#model.add(InceptionV3(include_top=False, pooling='max', weights='imagenet')) \t# entire resnet model is the first layer!\n",
    "\t#model.add(ResNet50(include_top=False, pooling='max', weights='imagenet')) \t\n",
    " \t#model.add(ResNet101(include_top=False, pooling='max', weights='imagenet')) \n",
    "\tmodel.add(MobileNetV2(include_top=False, pooling='max', weights='imagenet')) \t\n",
    " \t#model.add(DenseNet121(include_top=False, pooling='max', weights='imagenet'))\n",
    "\tmodel.add(Dense(ct_num_classes, activation='softmax'))\n",
    "\tmodel.layers[0].trainable = False\t\t# entire resnet layer is not trainable; only the final dense layer is trained\n",
    "\topt= keras.optimizers.Adam(learning_rate=0.1)\n",
    "\tmodel.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "\tmodel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "901fd169",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_per_epoch = ct_train_generator.samples // batch_size\n",
    "validation_steps = ct_validation_generator.samples // batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c852a291",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-05 21:23:19.890901: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8800\n",
      "2023-11-05 21:23:20.306774: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2023-11-05 21:23:20.397403: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x555e28be69e0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-11-05 21:23:20.397423: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA RTX A2000 8GB Laptop GPU, Compute Capability 8.6\n",
      "2023-11-05 21:23:20.424017: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 4/45 [=>............................] - ETA: 1s - loss: 93.5014 - accuracy: 0.6562 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-05 21:23:20.631221: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 5s 67ms/step - loss: 62.9027 - accuracy: 0.6542 - val_loss: 16.9009 - val_accuracy: 0.7913\n",
      "Epoch 2/15\n",
      "45/45 [==============================] - 3s 57ms/step - loss: 28.6680 - accuracy: 0.6778 - val_loss: 22.2390 - val_accuracy: 0.7893\n",
      "Epoch 3/15\n",
      "45/45 [==============================] - 3s 57ms/step - loss: 15.2043 - accuracy: 0.6750 - val_loss: 8.0161 - val_accuracy: 0.7893\n",
      "Epoch 4/15\n",
      "45/45 [==============================] - 3s 57ms/step - loss: 20.2183 - accuracy: 0.6625 - val_loss: 21.3670 - val_accuracy: 0.7893\n",
      "Epoch 5/15\n",
      "45/45 [==============================] - 3s 57ms/step - loss: 7.5600 - accuracy: 0.7236 - val_loss: 6.4985 - val_accuracy: 0.7903\n",
      "Epoch 6/15\n",
      "45/45 [==============================] - 3s 57ms/step - loss: 19.9048 - accuracy: 0.6639 - val_loss: 35.8600 - val_accuracy: 0.7903\n",
      "Epoch 7/15\n",
      "45/45 [==============================] - 3s 57ms/step - loss: 12.8141 - accuracy: 0.6972 - val_loss: 18.5965 - val_accuracy: 0.2631\n",
      "Epoch 8/15\n",
      "45/45 [==============================] - 3s 57ms/step - loss: 8.3095 - accuracy: 0.7028 - val_loss: 8.0232 - val_accuracy: 0.7923\n",
      "Epoch 9/15\n",
      "45/45 [==============================] - 3s 57ms/step - loss: 29.1568 - accuracy: 0.6861 - val_loss: 9.2156 - val_accuracy: 0.7893\n",
      "Epoch 10/15\n",
      "45/45 [==============================] - 3s 58ms/step - loss: 18.7077 - accuracy: 0.6778 - val_loss: 7.6402 - val_accuracy: 0.7913\n",
      "Epoch 11/15\n",
      "45/45 [==============================] - 3s 57ms/step - loss: 10.3984 - accuracy: 0.7069 - val_loss: 51.1756 - val_accuracy: 0.2117\n",
      "Epoch 12/15\n",
      "45/45 [==============================] - 3s 58ms/step - loss: 23.3607 - accuracy: 0.6514 - val_loss: 5.7038 - val_accuracy: 0.7933\n",
      "Epoch 13/15\n",
      "45/45 [==============================] - 3s 57ms/step - loss: 11.4111 - accuracy: 0.7097 - val_loss: 6.5806 - val_accuracy: 0.5716\n",
      "Epoch 14/15\n",
      "45/45 [==============================] - 3s 57ms/step - loss: 6.1828 - accuracy: 0.7347 - val_loss: 4.5362 - val_accuracy: 0.6492\n",
      "Epoch 15/15\n",
      "45/45 [==============================] - 3s 57ms/step - loss: 7.6306 - accuracy: 0.7306 - val_loss: 11.4429 - val_accuracy: 0.4345\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f7a48360dd0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    ct_train_generator,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    epochs=epoch_num,  # Use the previously defined epoch_num\n",
    "    validation_data=ct_validation_generator,\n",
    "    validation_steps=validation_steps,\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9418aca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 2s 22ms/step\n",
      "Equal Error Rate (EER) on validation set: 48.61%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "true_labels_validation = ct_validation_generator.classes  # True labels (0 or 1)\n",
    "predicted_probabilities_validation = model.predict(ct_validation_generator)  # Predicted probabilities for the positive class\n",
    "\n",
    "# Compute the ROC curve on the validation set\n",
    "fpr, tpr, thresholds = roc_curve(true_labels_validation, predicted_probabilities_validation[:, 1])\n",
    "eer_threshold = thresholds[np.argmin(np.abs(1 - tpr - fpr))]\n",
    "eer = fpr[np.argmin(np.abs(1 - tpr - fpr))] * 100  # EER as a percentage\n",
    "\n",
    "print(f\"Equal Error Rate (EER) on validation set: {eer:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "970b7c06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 [==============================] - 9s 80ms/step\n",
      "Accuracy: 0.26\n",
      "Precision: 0.20\n",
      "Recall: 0.90\n",
      "F1 Score: 0.33\n"
     ]
    }
   ],
   "source": [
    "predicted_probabilities = model.predict(ct_test_generator)[:, 1]  # Predicted probabilities for the positive class (spoofed)\n",
    "true_labels = ct_test_generator.classes  # True labels (0 for genuine, 1 for spoofed)\n",
    "threshold = eer_threshold  # You can adjust this threshold as needed\n",
    "binary_predictions = [1 if prob >= threshold else 0 for prob in predicted_probabilities]\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "accuracy = accuracy_score(true_labels, binary_predictions)\n",
    "precision = precision_score(true_labels, binary_predictions)\n",
    "recall = recall_score(true_labels, binary_predictions)\n",
    "f1 = f1_score(true_labels, binary_predictions)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1 Score: {f1:.2f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "35e069a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 [==============================] - 8s 75ms/step\n",
      "Half Total Error Rate (HTER) for Face Anti-Spoofing: 51.01%\n"
     ]
    }
   ],
   "source": [
    "# Evaluation for testing set for HTER\n",
    "predicted_probabilities = model.predict(ct_test_generator)[:, 1]  # Predicted probabilities for the positive class (spoofed)\n",
    "numericLabels = np.array([1 if label == 0 else 0 for label in true_labels])\n",
    "\n",
    "real_scores1 = predicted_probabilities[numericLabels == 1]\n",
    "attack_scores2 = predicted_probabilities[numericLabels == 0]\n",
    "\n",
    "threshold = eer_threshold  # Replace with your chosen threshold\n",
    "\n",
    "FAR = np.sum(attack_scores2 > threshold) / len(attack_scores2) * 100\n",
    "FRR = np.sum(real_scores1 <= threshold) / len(real_scores1) * 100\n",
    "HTER4 = (FAR + FRR) / 2\n",
    "\n",
    "# Display HTER\n",
    "print(f\"Half Total Error Rate (HTER) for Face Anti-Spoofing: {HTER4:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "t",
   "language": "python",
   "name": "t"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
