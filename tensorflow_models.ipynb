{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6a78f68",
   "metadata": {},
   "source": [
    "# An Analysis for face anti-spoofing of 20 different architectures in CNNs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8916ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Dropout, Flatten\n",
    "from keras.applications.resnet import ResNet50, ResNet101, preprocess_input\n",
    "from keras.applications import (\n",
    "    InceptionV3, ResNet50, ResNet101, MobileNetV2,\n",
    "    DenseNet121, VGG16, VGG19, DenseNet169,\n",
    "    DenseNet201, Xception, NASNetLarge, NASNetMobile,\n",
    "    EfficientNetB0, EfficientNetB1, EfficientNetB2,\n",
    "    EfficientNetB3, EfficientNetB4, EfficientNetB5,\n",
    "    EfficientNetB6, EfficientNetB7\n",
    ")\n",
    "from keras.preprocessing import image\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from sklearn.metrics import (\n",
    "    f1_score, precision_score, recall_score,\n",
    "    confusion_matrix, classification_report, roc_curve\n",
    ")\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6493d484",
   "metadata": {},
   "source": [
    "## Prepare datasets for training, validation and Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b391243",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set dataset paths\n",
    "ct_train_path = \"/data/Desktop//trainset/\"\n",
    "ct_validation_path = \"/data/Desktop/validation/\"\n",
    "ct_test_path = \"/data/Desktop/testset/\"\n",
    "\n",
    "# Number of classes depends on the dataset (2 for the binary classification)\n",
    "ct_num_classes = 2\n",
    "\n",
    "# Image size depends on the pretrained model (224 for InceptionV3)\n",
    "np.random.seed(42)\n",
    "image_size = 224\n",
    "batch_size = 16\n",
    "epoch_num = 15\n",
    "\n",
    "# Define a data generator for training set with data augmentation\n",
    "ct_train_datagen = image.ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    vertical_flip=True,\n",
    "    horizontal_flip=True,\n",
    "    preprocessing_function=preprocess_input)\n",
    "\n",
    "ct_train_generator = ct_train_datagen.flow_from_directory(\n",
    "    ct_train_path,\n",
    "    target_size=(image_size, image_size),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "# Define a data generator for validation set (without data augmentation)\n",
    "ct_validation_datagen = image.ImageDataGenerator(rescale=1./255, preprocessing_function=preprocess_input)\n",
    "\n",
    "ct_validation_generator = ct_validation_datagen.flow_from_directory(\n",
    "    ct_validation_path,\n",
    "    target_size=(image_size, image_size),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "# Define a data generator for testing set (without data augmentation)\n",
    "ct_test_datagen = image.ImageDataGenerator(rescale=1./255, preprocessing_function=preprocess_input)\n",
    "\n",
    "ct_test_generator = ct_test_datagen.flow_from_directory(\n",
    "    ct_test_path,\n",
    "    target_size=(image_size, image_size),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcbad27c",
   "metadata": {},
   "source": [
    "# Importing 20 pre-trained CNN models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda7b114",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Assuming image_size is set to 224\n",
    "input_shape = (224, 224, 3)  # Adjust according to the target size of your images\n",
    "\n",
    "# Create different models for comparison and choose the best model\n",
    "#base_model = InceptionV3(include_top=False, pooling='max', weights='imagenet', input_shape=input_shape)\n",
    "#base_model = ResNet50(include_top=False, pooling='max', weights='imagenet', input_shape=input_shape)\n",
    "#base_model = ResNet101(include_top=False, pooling='max', weights='imagenet', input_shape=input_shape)\n",
    "#base_model = MobileNetV2(include_top=False, pooling='max', weights='imagenet', input_shape=input_shape)\n",
    "#base_model = DenseNet121(include_top=False, pooling='max', weights='imagenet', input_shape=input_shape)\n",
    "#base_model = VGG16(include_top=False, pooling='max', weights='imagenet', input_shape=input_shape)\n",
    "#base_model = VGG19(include_top=False, pooling='max', weights='imagenet', input_shape=input_shape)\n",
    "#base_model = DenseNet169(include_top=False, pooling='max', weights='imagenet', input_shape=input_shape)\n",
    "#base_model = DenseNet201(include_top=False, pooling='max', weights='imagenet', input_shape=input_shape)\n",
    "#base_model = Xception(include_top=False, pooling='max', weights='imagenet', input_shape=input_shape)\n",
    "#base_model = NASNetLarge(include_top=False, weights='imagenet', input_shape=input_shape)\n",
    "#base_model = NASNetMobile(include_top=False, weights='imagenet', input_shape=input_shape)\n",
    "#base_model = EfficientNetB0(include_top=False, weights='imagenet', input_shape=input_shape)\n",
    "#base_model = EfficientNetB1(include_top=False, weights='imagenet', input_shape=input_shape)\n",
    "#base_model = EfficientNetB2(include_top=False, weights='imagenet', input_shape=input_shape)\n",
    "#base_model = EfficientNetB3(include_top=False, weights='imagenet', input_shape=input_shape)\n",
    "#base_model = EfficientNetB4(include_top=False, weights='imagenet', input_shape=input_shape)\n",
    "#base_model = EfficientNetB5(include_top=False, weights='imagenet', input_shape=input_shape)\n",
    "#base_model = EfficientNetB6(include_top=False, weights='imagenet', input_shape=input_shape)\n",
    "#base_model = EfficientNetB7(include_top=False, weights='imagenet', input_shape=input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "051e0a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Assuming image_size is set to 224\n",
    "input_shape = (224, 224, 3)  # Adjust according to the target size of your images\n",
    "\n",
    "# Create the EfficientNetB7 base (without the top layer)\n",
    "base_model = EfficientNetB7(include_top=False, pooling='max', weights='imagenet', input_shape=input_shape)\n",
    "\n",
    "# Freeze the weights of the EfficientNetB7 base\n",
    "base_model.trainable = False\n",
    "\n",
    "# Create the top layers for binary classification\n",
    "top_model = Sequential()\n",
    "top_model.add(Flatten())\n",
    "top_model.add(Dense(64, activation='relu'))\n",
    "top_model.add(Dense(ct_num_classes, activation='sigmoid'))  # Change to 'sigmoid' for binary classification\n",
    "\n",
    "# Combine the base and top models\n",
    "model = Sequential()\n",
    "model.add(base_model)\n",
    "model.add(top_model)\n",
    "\n",
    "# Compile the combined model\n",
    "opt = keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Display the model summary\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "901fd169",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model parameters\n",
    "steps_per_epoch = ct_train_generator.samples // batch_size\n",
    "validation_steps = ct_validation_generator.samples // batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe46d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have already defined ct_train_generator, ct_validation_generator, steps_per_epoch, epoch_num, and validation_steps\n",
    "\n",
    "# Train the model using the fit method\n",
    "history = model.fit(\n",
    "    ct_train_generator,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    epochs=epoch_num,\n",
    "    validation_data=ct_validation_generator,\n",
    "    validation_steps=validation_steps,\n",
    "    verbose=1\n",
    ")\n",
    "# Plot training and validation curves\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596f25f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Assuming you have the true labels for the validation and test sets\n",
    "true_labels_validation = ct_validation_generator.classes\n",
    "true_labels_test = ct_test_generator.classes\n",
    "\n",
    "# Assuming you have the predicted probabilities for the positive class (spoofed) from your model\n",
    "predicted_probabilities_validation = model.predict(ct_validation_generator)[:, 1]\n",
    "predicted_probabilities_test = model.predict(ct_test_generator)[:, 1]\n",
    "\n",
    "# Compute the ROC curve on the validation set\n",
    "fpr, tpr, thresholds = roc_curve(true_labels_validation, predicted_probabilities_validation, pos_label=1)\n",
    "\n",
    "# Calculate EER on the validation set\n",
    "eer = fpr[np.nanargmin(np.abs(fpr - (1 - tpr)))]\n",
    "\n",
    "# Find the threshold where FAR equals FRR (EER threshold)\n",
    "eer_threshold = thresholds[np.nanargmin(np.abs(fpr - (1 - tpr)))]\n",
    "\n",
    "# Apply the EER threshold to the test set predictions\n",
    "predictions_test = (predicted_probabilities_test > eer_threshold).astype(int)\n",
    "\n",
    "# Calculate HTER on the test set\n",
    "false_acceptance = np.sum((predictions_test == 1) & (true_labels_test == 0))\n",
    "false_rejection = np.sum((predictions_test == 0) & (true_labels_test == 1))\n",
    "total_samples_test = len(true_labels_test)\n",
    "\n",
    "hter = (false_acceptance + false_rejection) / (2 * total_samples_test)\n",
    "\n",
    "# Display EER and HTER\n",
    "print(f\"Equal Error Rate (EER) on validation set: {eer:.2%}\")\n",
    "print(f\"Half Total Error Rate (HTER) for Face Anti-Spoofing: {hter:.2%}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "t",
   "language": "python",
   "name": "t"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
